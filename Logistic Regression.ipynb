{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "28271adc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "7218f35a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_dataset(feature_file, label_file):\n",
    "    '''Read dataset in *.csv to dataframe in pandas'''\n",
    "    df_X = pd.read_csv(feature_file)\n",
    "    df_y = pd.read_csv(label_file)\n",
    "    X = df_X.values # convert values in dataframe to numpy array (feature)\n",
    "    y = df_y.values # convert values in dataframe to numpy array (label)\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "b5d1f804",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_features(X_train, X_test):\n",
    "    from sklearn.preprocessing import StandardScaler # import library \n",
    "    scaler = StandardScaler() # call an object function\n",
    "    scaler.fit(X_train)   # calculate mean, std in X_train  (x-u)/s\n",
    "    X_train_norm = scaler.transform(X_train)  # apply normalization on X_train\n",
    "    X_test_norm = scaler.transform(X_test)    # apply normalization on X_test\n",
    "    return X_train_norm, X_test_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "c5563c5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = read_dataset('Iris_X_train.csv', 'Iris_y_train.csv')\n",
    "X_test, y_test = read_dataset('Iris_X_test.csv', 'Iris_y_test.csv')\n",
    "X_train_norm, X_test_norm = normalize_features(X_train, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "aa78cf3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(112, 2)\n",
      "112\n"
     ]
    }
   ],
   "source": [
    "print(X_train_norm.shape)\n",
    "print(len(X_train_norm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "id": "1de5aecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Logistic_Reg:\n",
    "    def __init__(self, x, y, lr, ld):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        self.lr = lr\n",
    "        self.b = 0.\n",
    "        self.W = np.zeros([self.x.shape[1], 1])\n",
    "        self.ld = ld\n",
    "        \n",
    "    def sigmoid_func(self):\n",
    "        ex = np.dot(self.x, self.W)\n",
    "        self.sigmoid = 1/(1 + np.exp(-ex-self.b))\n",
    "        #print(self.sigmoid.shape)\n",
    "        \n",
    "    def regu_cost_func(self):\n",
    "        self.sigmoid_func()\n",
    "        self.cost = (np.sum(-self.y*np.log(self.sigmoid)) - np.sum((1 - self.y)*np.log(1 - self.sigmoid)))/self.x.shape[0]\n",
    "        self.regu = (self.ld/(2*self.x.shape[1]))*np.sum(np.dot(self.W.T, self.W))\n",
    "        self.cost_regu = self.cost + self.regu\n",
    "              \n",
    "    def gradDec(self):\n",
    "        #dL = (1/self.x.shape[0])*np.sum((self.sigmoid) - np.sum(self.y))*np.sum(self.x) + (self.ld*np.sum(self.W))\n",
    "        dW = 1/self.x.shape[0]*np.dot(self.x.T, self.sigmoid-self.y) + self.ld/self.x.shape[1]*self.W\n",
    "        db = 1/self.x.shape[0]*np.sum(self.sigmoid - self.y)\n",
    "        self.W = self.W - self.lr*dW\n",
    "        self.b = self.b - self.lr*db\n",
    "        \n",
    "    def predict(self, X_test):\n",
    "        self.sigmoid_test = 1/(1 + np.exp(-(np.dot(X_test, self.W))-self.b))\n",
    "        return np.where(self.sigmoid_test >=0.5, 1, 0)\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "id": "8c064b89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 100, current loss = 0.59745\n",
      "epoch = 200, current loss = 0.54486\n",
      "epoch = 300, current loss = 0.51422\n",
      "epoch = 400, current loss = 0.49537\n",
      "epoch = 500, current loss = 0.48323\n",
      "epoch = 600, current loss = 0.47513\n",
      "epoch = 700, current loss = 0.46957\n",
      "epoch = 800, current loss = 0.46567\n",
      "epoch = 900, current loss = 0.46289\n",
      "epoch = 1000, current loss = 0.46088\n"
     ]
    }
   ],
   "source": [
    "reglog = Logistic_Reg(X_train_norm, y_train, 0.01, 0.1)\n",
    "for i in range(1000):\n",
    "    reglog.sigmoid_func()\n",
    "    reglog.gradDec()\n",
    "    reglog.regu_cost_func()\n",
    "    if ((i+1)%100==0):\n",
    "        print('epoch = %d, current loss = %.5f'%(i+1, reglog.cost_regu))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "id": "3f1ed145",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8421052631578947\n"
     ]
    }
   ],
   "source": [
    "y_pred = reglog.predict(X_test_norm)\n",
    "print(float(sum(y_pred==y_test))/float(len(y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74bfc408",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b0c6814",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e513d54b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
